I've got a refit-apds module in (my copy of) EXOAnalysis, but it is severely time-consuming, with all of the time being taken up by either matrix-vector multiplication or matrix multiplication with skinny matrices.  I'm using BLAS, but gemm can't do much with skinny matrices, so the performance is still insufficient.

However, in fact the matrices we're multiplying by are reused many times -- so there should be much more opportunity for BLAS to help if I can "package" many skinny matrices into one fat one.  That requires packaging multiple EXOEventData events together and handling them in parallel, which EXOAnalysis can't accommodate.  Thus the need for a standalone version of the code.

This actually can also alleviate some of the pressure on me to re-implement clustering, grid corrections, gain corrections, and purity corrections -- after running the standalone program, we could just rerun the needed components of EXOAnalysis and accomplish these things.

Note that the whole matrix A is not identical event-by-event -- just the noise portions.  So, some care will need to be taken.  Additionally, I'll want to support events converging at different times.

Basic plan:  the class should have two matrices (column-major), one of which is designated the queue for vectors needing to be multiplied.  Each event needs to track where it put its own vectors in the matrix.  When it's time, matrix multiplication gets called, and results are put into a result matrix.  The queue matrix is cleared, ready to accept new requests.


Memory usage, for 40 simultaneous signals (fColumnLength ~ 3e5, max number of signals per event = 5):
fNoiseMulQueue:	3e5*40*8B = 			96 MB
fNoiseResultQueue:				96 MB
fWireDeposit: 512*10*8B =			negligible
fWireInduction:					negligible
fLightMaps: 80*40^3*8B =			41 MB
fGainMaps:
fNoiseDiag: 3e5*8B =				2.4 MB
fInvSqrtNoiseDiag:				2.4 MB
fNoiseCorrelations: 3e5*300*8B=			720 MB
EventHandler signal solvers: 6*40*3e5*8B =	576 MB
fWireModel: 40*2000*8B =			negligible
Workspace: 3e5*5*8B =				12 MB
fWFEvent: 226*2000*4B =				2 MB

So, I can only account for 1.6 GB; there's a mysterious 900 MB I can't locate...
Could it be libraries I'm linking with?  (Ie do they get loaded into memory?)

ToDO:

New high-priority tasks:
* Convert to use static linking.
	I'm attempting to rebuild my ROOT installation statically.
* Run from an executable on scratch, and with all files also on scratch.  (Use $GSCRATCH2)
* Understand why reading chunks from file crashes; add lots of assert statements to make sure I'm creating and reading the noise file properly.
O Test whether xrootd is currently working for raw root files at NERSC.
- I should overwrite fRawEnergy, for now anyway.


- Track down memory hogs -- where is all of the memory usage coming from exactly?
- Write up code (EXOAnalysis, EXOFitting, script) for getting a rotated resolution from a denoised file.
- Investigate whether I can reorganize preconditioners to be faster, since they're the non-noise bottleneck.
	I've added a watch to DoInvRPrecon, which should give valuable information.
* Verify that reasonable results are being produced by current code!!
- Improve noise matrix by exploiting symmetries.  (Are there any in DFT domain?)
- SLAC vs NERSC (it's looking like NERSC is necessary -- but it would be nice to give Tony a firm answer on this before asking he get xrootd working again).
- Make it possible to set a threshold on the command-line.
- Write up note in latex, explaining algorithm and implementation.

With the important goals of:
- Compare speeds at SLAC vs NERSC (various flavors at SLAC; don't bother with multithreaded NERSC MKL).
* Identify a proper threshold.
	As a secondary consideration, identify the preconditioned threshold and relative number of iterations.
* Verify whether I gain anything by including wires.
	If so, pin down exactly what is providing the gain -- better APD denoising, or wire denoising.

0 Mike is going to stress-test NERSC waveform access, to see what kind of combined waveform read speed is acheivable.
0 Mike will ask Tony to get a pipeline task set up at SLAC.


	The algorithms can be denoted by a box, where some plausible options are:

			Using APDs	Using Wires
	Denoise APDs	XXXXXXXXXX	XXXXXXXXXXX
	Denoise Wires	XXXXXXXXXX	XXXXXXXXXXX

			Using APDs	Using Wires
	Denoise APDs	XXXXXXXXXX
	Denoise Wires			XXXXXXXXXXX

			Using APDs	Using Wires
	Denoise APDs	XXXXXXXXXX	XXXXXXXXXXX
	Denoise Wires

			Using APDs	Using Wires
	Denoise APDs	XXXXXXXXXX
	Denoise Wires

	Each box filled in should give a strictly better result; the question is which boxes are negligible.






For efficient running on NERSC (edison or hopper), I need to have some kind of multi-threading which lets me run multi-threaded processes efficiently.  In all cases, I can achieve this most efficiently by managing the thread pools myself -- for noise multiplication I can dispatch frequency blocks to independent threads, and for the rest of solving I can handle whole events in parallel. This requires:

* Keep linking to the sequential version of MKL.
* Looping through BiCGSTAB finish-up, manage a pool of N threads and finish events one at a time.
	Use a lock on writing events to output.
	Use a lock on writing noise multiplication requests.
* Looping through frequency blocks of noise multiplication, manage a pool again.
* Keep event reading and initial estimation single-threaded for now.
* Replace the static global workspace with something thread-safe.
* Make watches thread-safe.  Check that ROOT shared structures (Lightmap, etc) can be read thread-safely.

Currently, to use threads I'm requiring "-DUSE_THREADS -DNUM_THREADS=6" or the like.

OK -- in principle I've done most of it.  What remains is ensuring all stopwatches are handled in sequential parts of the code, and ensuring other ROOT structures (lightmap etc) are not changing behind the scenes when I access them.

